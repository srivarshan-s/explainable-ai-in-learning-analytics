{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6710d7b3-fa86-4a5b-8d13-62564d1b2f6f",
   "metadata": {
    "id": "6710d7b3-fa86-4a5b-8d13-62564d1b2f6f",
    "tags": []
   },
   "source": [
    "### **ENVIRONMENT SETUP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c538f1bd-1dfd-40cb-b879-18ae87040a68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c538f1bd-1dfd-40cb-b879-18ae87040a68",
    "outputId": "a358a6f6-2284-4530-9866-845945b7b85b"
   },
   "outputs": [],
   "source": [
    "# ! rm -r data*\n",
    "# ! wget http://argumentation.bplaced.net/arguana-data/dagstuhl-15512-argquality-corpus-v2.zip\n",
    "# ! unzip dagstuhl-15512-argquality-corpus-v2.zip\n",
    "# ! rm *.zip\n",
    "# ! rm -r __MACOSX\n",
    "# ! mv dagstuhl-15512-argquality-corpus-v2 data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83563f1b-8033-472c-a0b3-f80ab3bca4d3",
   "metadata": {
    "id": "83563f1b-8033-472c-a0b3-f80ab3bca4d3",
    "tags": []
   },
   "source": [
    "### **IMPORT LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "053e67cb",
   "metadata": {
    "id": "053e67cb"
   },
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "\n",
    "import random\n",
    "random.seed(14071)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "783c9ed5-f941-4071-be7a-fa293a8d3322",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "783c9ed5-f941-4071-be7a-fa293a8d3322",
    "outputId": "1e7509e9-1899-4df9-f430-4b11ef5e0f7b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/sri/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/sri/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/sri/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/sri/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer # Bag of Words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # TF-IDF\n",
    "from sklearn.model_selection import cross_val_predict # Cross Validation\n",
    "from sklearn.model_selection import KFold # K Cross\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder # Label Encoding\n",
    "from sklearn.preprocessing import OneHotEncoder # One Hot Encoding\n",
    "\n",
    "from sklearn.model_selection import train_test_split # Train Test Split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression # LR Model\n",
    "from sklearn.tree import DecisionTreeClassifier # DT Model\n",
    "from sklearn.ensemble import RandomForestClassifier # RF Model\n",
    "\n",
    "import tensorflow as tf # Tensorflow bindings\n",
    "from tensorflow import keras # Keras bindings\n",
    "\n",
    "from sklearn.metrics import classification_report # Classification Report\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV # Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b9c60c-7a43-45f6-b0a7-6d6f7168694a",
   "metadata": {
    "id": "89b9c60c-7a43-45f6-b0a7-6d6f7168694a",
    "tags": []
   },
   "source": [
    "### **IMPORT DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb6e164d-d720-46c7-bf3d-c2348faa8e76",
   "metadata": {
    "id": "fb6e164d-d720-46c7-bf3d-c2348faa8e76"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/dagstuhl-15512-argquality-corpus-annotated.csv\", sep='\\t', encoding_errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ca0865b-8f18-46fe-9997-2556d7db469b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5ca0865b-8f18-46fe-9997-2556d7db469b",
    "outputId": "aa4e8df6-b3ed-4ae7-fb2b-07eaa5c38204"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator</th>\n",
       "      <th>argumentative</th>\n",
       "      <th>overall quality</th>\n",
       "      <th>local acceptability</th>\n",
       "      <th>appropriateness</th>\n",
       "      <th>arrangement</th>\n",
       "      <th>clarity</th>\n",
       "      <th>cogency</th>\n",
       "      <th>effectiveness</th>\n",
       "      <th>global acceptability</th>\n",
       "      <th>...</th>\n",
       "      <th>global sufficiency</th>\n",
       "      <th>reasonableness</th>\n",
       "      <th>local relevance</th>\n",
       "      <th>credibility</th>\n",
       "      <th>emotional appeal</th>\n",
       "      <th>sufficiency</th>\n",
       "      <th>argument</th>\n",
       "      <th>#id</th>\n",
       "      <th>issue</th>\n",
       "      <th>stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>y</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>...</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>it is true that bottled water is a waste, but ...</td>\n",
       "      <td>arg219250</td>\n",
       "      <td>ban-plastic-water-bottles</td>\n",
       "      <td>no-bad-for-the-economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>y</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>3 (High)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>3 (High)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>3 (High)</td>\n",
       "      <td>...</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>it is true that bottled water is a waste, but ...</td>\n",
       "      <td>arg219250</td>\n",
       "      <td>ban-plastic-water-bottles</td>\n",
       "      <td>no-bad-for-the-economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>y</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>...</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>3 (High)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>it is true that bottled water is a waste, but ...</td>\n",
       "      <td>arg219250</td>\n",
       "      <td>ban-plastic-water-bottles</td>\n",
       "      <td>no-bad-for-the-economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>y</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>3 (High)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>...</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>3 (High)</td>\n",
       "      <td>3 (High)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>Most Americans on average recycle 86-88% of th...</td>\n",
       "      <td>arg219293</td>\n",
       "      <td>ban-plastic-water-bottles</td>\n",
       "      <td>no-bad-for-the-economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>y</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>...</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>Most Americans on average recycle 86-88% of th...</td>\n",
       "      <td>arg219293</td>\n",
       "      <td>ban-plastic-water-bottles</td>\n",
       "      <td>no-bad-for-the-economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>2</td>\n",
       "      <td>y</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>3 (High)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>3 (High)</td>\n",
       "      <td>...</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>Raffles neglected Singapore when he went aroun...</td>\n",
       "      <td>arg168822</td>\n",
       "      <td>william-farquhar-ought-to-be-honoured-as-the-r...</td>\n",
       "      <td>yes-of-course</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>3</td>\n",
       "      <td>y</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>...</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>3 (High)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>Raffles neglected Singapore when he went aroun...</td>\n",
       "      <td>arg168822</td>\n",
       "      <td>william-farquhar-ought-to-be-honoured-as-the-r...</td>\n",
       "      <td>yes-of-course</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>1</td>\n",
       "      <td>y</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>...</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>3 (High)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>Raffles doesn't care about the citizens, doesn...</td>\n",
       "      <td>arg168834</td>\n",
       "      <td>william-farquhar-ought-to-be-honoured-as-the-r...</td>\n",
       "      <td>yes-of-course</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>2</td>\n",
       "      <td>y</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>3 (High)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>3 (High)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>...</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>3 (High)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>Raffles doesn't care about the citizens, doesn...</td>\n",
       "      <td>arg168834</td>\n",
       "      <td>william-farquhar-ought-to-be-honoured-as-the-r...</td>\n",
       "      <td>yes-of-course</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>3</td>\n",
       "      <td>y</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>...</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>3 (High)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>Raffles doesn't care about the citizens, doesn...</td>\n",
       "      <td>arg168834</td>\n",
       "      <td>william-farquhar-ought-to-be-honoured-as-the-r...</td>\n",
       "      <td>yes-of-course</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>960 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     annotator argumentative overall quality local acceptability  \\\n",
       "0            1             y         1 (Low)             1 (Low)   \n",
       "1            2             y         1 (Low)            3 (High)   \n",
       "2            3             y     2 (Average)         2 (Average)   \n",
       "3            1             y     2 (Average)            3 (High)   \n",
       "4            2             y         1 (Low)         2 (Average)   \n",
       "..         ...           ...             ...                 ...   \n",
       "955          2             y     2 (Average)         2 (Average)   \n",
       "956          3             y     2 (Average)         2 (Average)   \n",
       "957          1             y     2 (Average)         2 (Average)   \n",
       "958          2             y     2 (Average)         2 (Average)   \n",
       "959          3             y     2 (Average)         2 (Average)   \n",
       "\n",
       "    appropriateness  arrangement      clarity      cogency effectiveness  \\\n",
       "0           1 (Low)      1 (Low)  2 (Average)      1 (Low)       1 (Low)   \n",
       "1       2 (Average)  2 (Average)     3 (High)      1 (Low)       1 (Low)   \n",
       "2       2 (Average)  2 (Average)  2 (Average)  2 (Average)   2 (Average)   \n",
       "3       2 (Average)  2 (Average)  2 (Average)  2 (Average)   2 (Average)   \n",
       "4           1 (Low)  2 (Average)  2 (Average)      1 (Low)       1 (Low)   \n",
       "..              ...          ...          ...          ...           ...   \n",
       "955        3 (High)  2 (Average)  2 (Average)      1 (Low)       1 (Low)   \n",
       "956     2 (Average)  2 (Average)  2 (Average)  2 (Average)   2 (Average)   \n",
       "957     2 (Average)  2 (Average)      1 (Low)  2 (Average)   2 (Average)   \n",
       "958        3 (High)  2 (Average)     3 (High)      1 (Low)   2 (Average)   \n",
       "959     2 (Average)  2 (Average)  2 (Average)  2 (Average)   2 (Average)   \n",
       "\n",
       "    global acceptability  ... global sufficiency reasonableness  \\\n",
       "0                1 (Low)  ...            1 (Low)        1 (Low)   \n",
       "1               3 (High)  ...            1 (Low)    2 (Average)   \n",
       "2            2 (Average)  ...        2 (Average)    2 (Average)   \n",
       "3            2 (Average)  ...        2 (Average)    2 (Average)   \n",
       "4            2 (Average)  ...            1 (Low)        1 (Low)   \n",
       "..                   ...  ...                ...            ...   \n",
       "955             3 (High)  ...            1 (Low)    2 (Average)   \n",
       "956          2 (Average)  ...        2 (Average)    2 (Average)   \n",
       "957          2 (Average)  ...        2 (Average)    2 (Average)   \n",
       "958          2 (Average)  ...            1 (Low)    2 (Average)   \n",
       "959          2 (Average)  ...        2 (Average)    2 (Average)   \n",
       "\n",
       "    local relevance  credibility emotional appeal  sufficiency  \\\n",
       "0           1 (Low)      1 (Low)          1 (Low)      1 (Low)   \n",
       "1       2 (Average)  2 (Average)      2 (Average)      1 (Low)   \n",
       "2          3 (High)  2 (Average)          1 (Low)  2 (Average)   \n",
       "3          3 (High)     3 (High)      2 (Average)  2 (Average)   \n",
       "4       2 (Average)  2 (Average)      2 (Average)      1 (Low)   \n",
       "..              ...          ...              ...          ...   \n",
       "955     2 (Average)  2 (Average)      2 (Average)      1 (Low)   \n",
       "956        3 (High)  2 (Average)      2 (Average)  2 (Average)   \n",
       "957        3 (High)  2 (Average)      2 (Average)  2 (Average)   \n",
       "958     2 (Average)  2 (Average)         3 (High)      1 (Low)   \n",
       "959        3 (High)  2 (Average)      2 (Average)  2 (Average)   \n",
       "\n",
       "                                              argument        #id  \\\n",
       "0    it is true that bottled water is a waste, but ...  arg219250   \n",
       "1    it is true that bottled water is a waste, but ...  arg219250   \n",
       "2    it is true that bottled water is a waste, but ...  arg219250   \n",
       "3    Most Americans on average recycle 86-88% of th...  arg219293   \n",
       "4    Most Americans on average recycle 86-88% of th...  arg219293   \n",
       "..                                                 ...        ...   \n",
       "955  Raffles neglected Singapore when he went aroun...  arg168822   \n",
       "956  Raffles neglected Singapore when he went aroun...  arg168822   \n",
       "957  Raffles doesn't care about the citizens, doesn...  arg168834   \n",
       "958  Raffles doesn't care about the citizens, doesn...  arg168834   \n",
       "959  Raffles doesn't care about the citizens, doesn...  arg168834   \n",
       "\n",
       "                                                 issue                  stance  \n",
       "0                            ban-plastic-water-bottles  no-bad-for-the-economy  \n",
       "1                            ban-plastic-water-bottles  no-bad-for-the-economy  \n",
       "2                            ban-plastic-water-bottles  no-bad-for-the-economy  \n",
       "3                            ban-plastic-water-bottles  no-bad-for-the-economy  \n",
       "4                            ban-plastic-water-bottles  no-bad-for-the-economy  \n",
       "..                                                 ...                     ...  \n",
       "955  william-farquhar-ought-to-be-honoured-as-the-r...           yes-of-course  \n",
       "956  william-farquhar-ought-to-be-honoured-as-the-r...           yes-of-course  \n",
       "957  william-farquhar-ought-to-be-honoured-as-the-r...           yes-of-course  \n",
       "958  william-farquhar-ought-to-be-honoured-as-the-r...           yes-of-course  \n",
       "959  william-farquhar-ought-to-be-honoured-as-the-r...           yes-of-course  \n",
       "\n",
       "[960 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31b790b0-bf9f-47a7-8550-ca2089cf0d66",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31b790b0-bf9f-47a7-8550-ca2089cf0d66",
    "outputId": "ae51365e-7e3e-4cde-d06e-7e8d0df92355"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of annotations = 960\n",
      "Number of unique arguements = 320\n",
      "Number of unique issue = 16\n",
      "Number of unique stance = 28\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of annotations = {len(df['argument'])}\")\n",
    "print(f\"Number of unique arguements = {len(np.unique(df['argument']))}\") # Each argument was scored by 3 annotators\n",
    "print(f\"Number of unique issue = {len(np.unique(df['issue']))}\")  # There are a total of 16 issues\n",
    "print(f\"Number of unique stance = {len(np.unique(df['stance']))}\") # Each issue has on an avg 2 stance (positive and negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fda0a9-19b5-41e3-a643-2174719c86e5",
   "metadata": {
    "id": "78fda0a9-19b5-41e3-a643-2174719c86e5",
    "tags": []
   },
   "source": [
    "### **DATA CLEANING**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a5f9aa-7e05-407e-a166-e4ea51af7f23",
   "metadata": {
    "id": "a9a5f9aa-7e05-407e-a166-e4ea51af7f23",
    "tags": []
   },
   "source": [
    "#### Remove statements are that are tagged as NOT argumentative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8ecab47-dc9a-496b-8a36-74a14b8ae88c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "a8ecab47-dc9a-496b-8a36-74a14b8ae88c",
    "outputId": "437b0dcf-97d8-4f20-e04d-be1db64671b2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator</th>\n",
       "      <th>argumentative</th>\n",
       "      <th>overall quality</th>\n",
       "      <th>local acceptability</th>\n",
       "      <th>appropriateness</th>\n",
       "      <th>arrangement</th>\n",
       "      <th>clarity</th>\n",
       "      <th>cogency</th>\n",
       "      <th>effectiveness</th>\n",
       "      <th>global acceptability</th>\n",
       "      <th>...</th>\n",
       "      <th>global sufficiency</th>\n",
       "      <th>reasonableness</th>\n",
       "      <th>local relevance</th>\n",
       "      <th>credibility</th>\n",
       "      <th>emotional appeal</th>\n",
       "      <th>sufficiency</th>\n",
       "      <th>argument</th>\n",
       "      <th>#id</th>\n",
       "      <th>issue</th>\n",
       "      <th>stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We will be able to ban water bottles until we ...</td>\n",
       "      <td>arg219242</td>\n",
       "      <td>ban-plastic-water-bottles</td>\n",
       "      <td>no-bad-for-the-economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The high price of bottled water is not the wat...</td>\n",
       "      <td>arg219232</td>\n",
       "      <td>ban-plastic-water-bottles</td>\n",
       "      <td>yes-emergencies-only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A drop of water is worth more than a sack of g...</td>\n",
       "      <td>arg219210</td>\n",
       "      <td>ban-plastic-water-bottles</td>\n",
       "      <td>yes-emergencies-only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yeah I have a bottle of water next to me its n...</td>\n",
       "      <td>arg219292</td>\n",
       "      <td>ban-plastic-water-bottles</td>\n",
       "      <td>yes-emergencies-only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yeah I have a bottle of water next to me its n...</td>\n",
       "      <td>arg219292</td>\n",
       "      <td>ban-plastic-water-bottles</td>\n",
       "      <td>yes-emergencies-only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>3</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yeah I have a bottle of water next to me its n...</td>\n",
       "      <td>arg219292</td>\n",
       "      <td>ban-plastic-water-bottles</td>\n",
       "      <td>yes-emergencies-only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This is just wrong we should not insult who we...</td>\n",
       "      <td>arg236317</td>\n",
       "      <td>christianity-or-atheism</td>\n",
       "      <td>christianity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>3</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I have a personal relationship with Christ. I ...</td>\n",
       "      <td>arg317490</td>\n",
       "      <td>christianity-or-atheism</td>\n",
       "      <td>christianity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>God helps those who help themselves! So i will...</td>\n",
       "      <td>arg234318</td>\n",
       "      <td>christianity-or-atheism</td>\n",
       "      <td>christianity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>God helps those who help themselves! So i will...</td>\n",
       "      <td>arg234318</td>\n",
       "      <td>christianity-or-atheism</td>\n",
       "      <td>christianity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>3</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>God helps those who help themselves! So i will...</td>\n",
       "      <td>arg234318</td>\n",
       "      <td>christianity-or-atheism</td>\n",
       "      <td>christianity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>3</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I was raised in a Freewill Baptist Church and ...</td>\n",
       "      <td>arg236641</td>\n",
       "      <td>christianity-or-atheism</td>\n",
       "      <td>christianity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>3</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I found more peace in my belief and will conti...</td>\n",
       "      <td>arg230311</td>\n",
       "      <td>christianity-or-atheism</td>\n",
       "      <td>christianity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>If evealution is real find me someone/somethin...</td>\n",
       "      <td>70818</td>\n",
       "      <td>evolution-vs-creation</td>\n",
       "      <td>creation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Could a unproven higher power have created a p...</td>\n",
       "      <td>68938</td>\n",
       "      <td>evolution-vs-creation</td>\n",
       "      <td>creation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Could a unproven higher power have created a p...</td>\n",
       "      <td>68938</td>\n",
       "      <td>evolution-vs-creation</td>\n",
       "      <td>creation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>3</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Could a unproven higher power have created a p...</td>\n",
       "      <td>68938</td>\n",
       "      <td>evolution-vs-creation</td>\n",
       "      <td>creation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our world could be a giant hologram &lt;br/&gt; http...</td>\n",
       "      <td>44125</td>\n",
       "      <td>evolution-vs-creation</td>\n",
       "      <td>creation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unfortunately, most of what sabrejimmy says is...</td>\n",
       "      <td>804</td>\n",
       "      <td>evolution-vs-creation</td>\n",
       "      <td>evolution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>3</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Most of the government sites in India is desig...</td>\n",
       "      <td>71467</td>\n",
       "      <td>firefox-vs-internet-explorer</td>\n",
       "      <td>there-s-more-browsers-than-the-ie-firefox-is-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The \"who gives a crap\" button was your browser...</td>\n",
       "      <td>541</td>\n",
       "      <td>gay-marriage-right-or-wrong</td>\n",
       "      <td>allowing-gay-marriage-is-right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>2</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The \"who gives a crap\" button was your browser...</td>\n",
       "      <td>541</td>\n",
       "      <td>gay-marriage-right-or-wrong</td>\n",
       "      <td>allowing-gay-marriage-is-right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>3</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The \"who gives a crap\" button was your browser...</td>\n",
       "      <td>541</td>\n",
       "      <td>gay-marriage-right-or-wrong</td>\n",
       "      <td>allowing-gay-marriage-is-right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>2</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stupid india they actually really suck. so, BO...</td>\n",
       "      <td>arg155750</td>\n",
       "      <td>india-has-the-potential-to-lead-the-world</td>\n",
       "      <td>no-against</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stupid india they actually really suck. so, BO...</td>\n",
       "      <td>arg155750</td>\n",
       "      <td>india-has-the-potential-to-lead-the-world</td>\n",
       "      <td>no-against</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     annotator argumentative overall quality local acceptability  \\\n",
       "25           2             n             NaN                 NaN   \n",
       "32           3             n             NaN                 NaN   \n",
       "37           2             n             NaN                 NaN   \n",
       "51           1             n             NaN                 NaN   \n",
       "52           2             n             NaN                 NaN   \n",
       "53           3             n             NaN                 NaN   \n",
       "97           2             n             NaN                 NaN   \n",
       "104          3             n             NaN                 NaN   \n",
       "105          1             n             NaN                 NaN   \n",
       "106          2             n             NaN                 NaN   \n",
       "107          3             n             NaN                 NaN   \n",
       "110          3             n             NaN                 NaN   \n",
       "113          3             n             NaN                 NaN   \n",
       "121          2             n             NaN                 NaN   \n",
       "126          1             n             NaN                 NaN   \n",
       "127          2             n             NaN                 NaN   \n",
       "128          3             n             NaN                 NaN   \n",
       "148          2             n             NaN                 NaN   \n",
       "162          1             n             NaN                 NaN   \n",
       "233          3             n             NaN                 NaN   \n",
       "264          1             n             NaN                 NaN   \n",
       "265          2             n             NaN                 NaN   \n",
       "266          3             n             NaN                 NaN   \n",
       "441          2             n             NaN                 NaN   \n",
       "442          1             n             NaN                 NaN   \n",
       "\n",
       "    appropriateness arrangement clarity cogency effectiveness  \\\n",
       "25              NaN         NaN     NaN     NaN           NaN   \n",
       "32              NaN         NaN     NaN     NaN           NaN   \n",
       "37              NaN         NaN     NaN     NaN           NaN   \n",
       "51              NaN         NaN     NaN     NaN           NaN   \n",
       "52              NaN         NaN     NaN     NaN           NaN   \n",
       "53              NaN         NaN     NaN     NaN           NaN   \n",
       "97              NaN         NaN     NaN     NaN           NaN   \n",
       "104             NaN         NaN     NaN     NaN           NaN   \n",
       "105             NaN         NaN     NaN     NaN           NaN   \n",
       "106             NaN         NaN     NaN     NaN           NaN   \n",
       "107             NaN         NaN     NaN     NaN           NaN   \n",
       "110             NaN         NaN     NaN     NaN           NaN   \n",
       "113             NaN         NaN     NaN     NaN           NaN   \n",
       "121             NaN         NaN     NaN     NaN           NaN   \n",
       "126             NaN         NaN     NaN     NaN           NaN   \n",
       "127             NaN         NaN     NaN     NaN           NaN   \n",
       "128             NaN         NaN     NaN     NaN           NaN   \n",
       "148             NaN         NaN     NaN     NaN           NaN   \n",
       "162             NaN         NaN     NaN     NaN           NaN   \n",
       "233             NaN         NaN     NaN     NaN           NaN   \n",
       "264             NaN         NaN     NaN     NaN           NaN   \n",
       "265             NaN         NaN     NaN     NaN           NaN   \n",
       "266             NaN         NaN     NaN     NaN           NaN   \n",
       "441             NaN         NaN     NaN     NaN           NaN   \n",
       "442             NaN         NaN     NaN     NaN           NaN   \n",
       "\n",
       "    global acceptability  ... global sufficiency reasonableness  \\\n",
       "25                   NaN  ...                NaN            NaN   \n",
       "32                   NaN  ...                NaN            NaN   \n",
       "37                   NaN  ...                NaN            NaN   \n",
       "51                   NaN  ...                NaN            NaN   \n",
       "52                   NaN  ...                NaN            NaN   \n",
       "53                   NaN  ...                NaN            NaN   \n",
       "97                   NaN  ...                NaN            NaN   \n",
       "104                  NaN  ...                NaN            NaN   \n",
       "105                  NaN  ...                NaN            NaN   \n",
       "106                  NaN  ...                NaN            NaN   \n",
       "107                  NaN  ...                NaN            NaN   \n",
       "110                  NaN  ...                NaN            NaN   \n",
       "113                  NaN  ...                NaN            NaN   \n",
       "121                  NaN  ...                NaN            NaN   \n",
       "126                  NaN  ...                NaN            NaN   \n",
       "127                  NaN  ...                NaN            NaN   \n",
       "128                  NaN  ...                NaN            NaN   \n",
       "148                  NaN  ...                NaN            NaN   \n",
       "162                  NaN  ...                NaN            NaN   \n",
       "233                  NaN  ...                NaN            NaN   \n",
       "264                  NaN  ...                NaN            NaN   \n",
       "265                  NaN  ...                NaN            NaN   \n",
       "266                  NaN  ...                NaN            NaN   \n",
       "441                  NaN  ...                NaN            NaN   \n",
       "442                  NaN  ...                NaN            NaN   \n",
       "\n",
       "    local relevance credibility emotional appeal sufficiency  \\\n",
       "25              NaN         NaN              NaN         NaN   \n",
       "32              NaN         NaN              NaN         NaN   \n",
       "37              NaN         NaN              NaN         NaN   \n",
       "51              NaN         NaN              NaN         NaN   \n",
       "52              NaN         NaN              NaN         NaN   \n",
       "53              NaN         NaN              NaN         NaN   \n",
       "97              NaN         NaN              NaN         NaN   \n",
       "104             NaN         NaN              NaN         NaN   \n",
       "105             NaN         NaN              NaN         NaN   \n",
       "106             NaN         NaN              NaN         NaN   \n",
       "107             NaN         NaN              NaN         NaN   \n",
       "110             NaN         NaN              NaN         NaN   \n",
       "113             NaN         NaN              NaN         NaN   \n",
       "121             NaN         NaN              NaN         NaN   \n",
       "126             NaN         NaN              NaN         NaN   \n",
       "127             NaN         NaN              NaN         NaN   \n",
       "128             NaN         NaN              NaN         NaN   \n",
       "148             NaN         NaN              NaN         NaN   \n",
       "162             NaN         NaN              NaN         NaN   \n",
       "233             NaN         NaN              NaN         NaN   \n",
       "264             NaN         NaN              NaN         NaN   \n",
       "265             NaN         NaN              NaN         NaN   \n",
       "266             NaN         NaN              NaN         NaN   \n",
       "441             NaN         NaN              NaN         NaN   \n",
       "442             NaN         NaN              NaN         NaN   \n",
       "\n",
       "                                              argument        #id  \\\n",
       "25   We will be able to ban water bottles until we ...  arg219242   \n",
       "32   The high price of bottled water is not the wat...  arg219232   \n",
       "37   A drop of water is worth more than a sack of g...  arg219210   \n",
       "51   Yeah I have a bottle of water next to me its n...  arg219292   \n",
       "52   Yeah I have a bottle of water next to me its n...  arg219292   \n",
       "53   Yeah I have a bottle of water next to me its n...  arg219292   \n",
       "97   This is just wrong we should not insult who we...  arg236317   \n",
       "104  I have a personal relationship with Christ. I ...  arg317490   \n",
       "105  God helps those who help themselves! So i will...  arg234318   \n",
       "106  God helps those who help themselves! So i will...  arg234318   \n",
       "107  God helps those who help themselves! So i will...  arg234318   \n",
       "110  I was raised in a Freewill Baptist Church and ...  arg236641   \n",
       "113  I found more peace in my belief and will conti...  arg230311   \n",
       "121  If evealution is real find me someone/somethin...      70818   \n",
       "126  Could a unproven higher power have created a p...      68938   \n",
       "127  Could a unproven higher power have created a p...      68938   \n",
       "128  Could a unproven higher power have created a p...      68938   \n",
       "148  Our world could be a giant hologram <br/> http...      44125   \n",
       "162  Unfortunately, most of what sabrejimmy says is...        804   \n",
       "233  Most of the government sites in India is desig...      71467   \n",
       "264  The \"who gives a crap\" button was your browser...        541   \n",
       "265  The \"who gives a crap\" button was your browser...        541   \n",
       "266  The \"who gives a crap\" button was your browser...        541   \n",
       "441  stupid india they actually really suck. so, BO...  arg155750   \n",
       "442  stupid india they actually really suck. so, BO...  arg155750   \n",
       "\n",
       "                                         issue  \\\n",
       "25                   ban-plastic-water-bottles   \n",
       "32                   ban-plastic-water-bottles   \n",
       "37                   ban-plastic-water-bottles   \n",
       "51                   ban-plastic-water-bottles   \n",
       "52                   ban-plastic-water-bottles   \n",
       "53                   ban-plastic-water-bottles   \n",
       "97                     christianity-or-atheism   \n",
       "104                    christianity-or-atheism   \n",
       "105                    christianity-or-atheism   \n",
       "106                    christianity-or-atheism   \n",
       "107                    christianity-or-atheism   \n",
       "110                    christianity-or-atheism   \n",
       "113                    christianity-or-atheism   \n",
       "121                      evolution-vs-creation   \n",
       "126                      evolution-vs-creation   \n",
       "127                      evolution-vs-creation   \n",
       "128                      evolution-vs-creation   \n",
       "148                      evolution-vs-creation   \n",
       "162                      evolution-vs-creation   \n",
       "233               firefox-vs-internet-explorer   \n",
       "264                gay-marriage-right-or-wrong   \n",
       "265                gay-marriage-right-or-wrong   \n",
       "266                gay-marriage-right-or-wrong   \n",
       "441  india-has-the-potential-to-lead-the-world   \n",
       "442  india-has-the-potential-to-lead-the-world   \n",
       "\n",
       "                                                stance  \n",
       "25                              no-bad-for-the-economy  \n",
       "32                                yes-emergencies-only  \n",
       "37                                yes-emergencies-only  \n",
       "51                                yes-emergencies-only  \n",
       "52                                yes-emergencies-only  \n",
       "53                                yes-emergencies-only  \n",
       "97                                        christianity  \n",
       "104                                       christianity  \n",
       "105                                       christianity  \n",
       "106                                       christianity  \n",
       "107                                       christianity  \n",
       "110                                       christianity  \n",
       "113                                       christianity  \n",
       "121                                           creation  \n",
       "126                                           creation  \n",
       "127                                           creation  \n",
       "128                                           creation  \n",
       "148                                           creation  \n",
       "162                                          evolution  \n",
       "233  there-s-more-browsers-than-the-ie-firefox-is-a...  \n",
       "264                     allowing-gay-marriage-is-right  \n",
       "265                     allowing-gay-marriage-is-right  \n",
       "266                     allowing-gay-marriage-is-right  \n",
       "441                                         no-against  \n",
       "442                                         no-against  \n",
       "\n",
       "[25 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"argumentative\"] == \"n\"] # Statements that are tagged as NOT argumentative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1958683-a560-4572-b58c-5ec9d4e92dec",
   "metadata": {
    "id": "b1958683-a560-4572-b58c-5ec9d4e92dec"
   },
   "outputs": [],
   "source": [
    "statements = df[df[\"argumentative\"] == \"n\"][\"argument\"].to_numpy() # Extract the statements\n",
    "statements = np.unique(statements) # Extract the unique statements\n",
    "\n",
    "for ele in statements: # Remove all occurrences of NOT argumentative statements\n",
    "    df.drop(df[df['argument'] == ele].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c473424f-f4c4-4416-b8d2-5b74d25b8528",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "id": "c473424f-f4c4-4416-b8d2-5b74d25b8528",
    "outputId": "4ecd4938-503d-4247-dfe8-2000fe66d48f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator</th>\n",
       "      <th>argumentative</th>\n",
       "      <th>overall quality</th>\n",
       "      <th>local acceptability</th>\n",
       "      <th>appropriateness</th>\n",
       "      <th>arrangement</th>\n",
       "      <th>clarity</th>\n",
       "      <th>cogency</th>\n",
       "      <th>effectiveness</th>\n",
       "      <th>global acceptability</th>\n",
       "      <th>...</th>\n",
       "      <th>global sufficiency</th>\n",
       "      <th>reasonableness</th>\n",
       "      <th>local relevance</th>\n",
       "      <th>credibility</th>\n",
       "      <th>emotional appeal</th>\n",
       "      <th>sufficiency</th>\n",
       "      <th>argument</th>\n",
       "      <th>#id</th>\n",
       "      <th>issue</th>\n",
       "      <th>stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [annotator, argumentative, overall quality, local acceptability, appropriateness, arrangement, clarity, cogency, effectiveness, global acceptability, global relevance, global sufficiency, reasonableness, local relevance, credibility, emotional appeal, sufficiency, argument, #id, issue, stance]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"argumentative\"] == \"n\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f14798e-4f94-478a-bc34-41eae3d158f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0f14798e-4f94-478a-bc34-41eae3d158f0",
    "outputId": "7fdc6a53-0bf8-4c75-ed30-f522609b588c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of annotations = 912\n",
      "Number of unique arguements = 304\n",
      "Number of unique issue = 16\n",
      "Number of unique stance = 28\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of annotations = {len(df['argument'])}\")\n",
    "print(f\"Number of unique arguements = {len(np.unique(df['argument']))}\") # Each argument was scored by 3 annotators\n",
    "print(f\"Number of unique issue = {len(np.unique(df['issue']))}\")  # There are a total of 16 issues\n",
    "print(f\"Number of unique stance = {len(np.unique(df['stance']))}\") # Each issue has on an avg 2 stance (positive and negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae3a0bd-f99b-447f-a1dc-4cead1c449a8",
   "metadata": {
    "id": "cae3a0bd-f99b-447f-a1dc-4cead1c449a8"
   },
   "source": [
    "#### Combine all Annotators' scores into a single score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2ec25ec-df7e-4084-bb79-637a89afc57c",
   "metadata": {
    "id": "d2ec25ec-df7e-4084-bb79-637a89afc57c"
   },
   "outputs": [],
   "source": [
    "argument = np.unique(df[\"argument\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "805bc96e-50d8-46b8-9e14-2b8f2b480c45",
   "metadata": {
    "id": "805bc96e-50d8-46b8-9e14-2b8f2b480c45"
   },
   "outputs": [],
   "source": [
    "attributes = [\"annotator\", \"overall quality\", \"cogency\", \"effectiveness\", \"reasonableness\", \"argument\", \"#id\"]\n",
    "\n",
    "cleaned_df = []\n",
    "\n",
    "for arg in argument:\n",
    "\n",
    "    new_df = df[df[\"argument\"] == arg][attributes]\n",
    "    flag = 0\n",
    "    new_dict = {\n",
    "        \"#id\": new_df[\"#id\"].iloc[0],\n",
    "        \"argument\": new_df[\"argument\"].iloc[0],\n",
    "    }\n",
    "\n",
    "    for ele in [\"overall quality\", \"cogency\", \"effectiveness\", \"reasonableness\"]:\n",
    "        if len(pd.value_counts(new_df[ele])) == 3:\n",
    "            flag = 1\n",
    "            break\n",
    "        new_dict[ele] = pd.value_counts(new_df[ele]).index[0]\n",
    "        \n",
    "    if flag == 1:\n",
    "        continue\n",
    "    cleaned_df.append(new_dict)\n",
    "\n",
    "cleaned_df = pd.DataFrame(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "524ecddd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "id": "524ecddd",
    "outputId": "e179211f-4220-44d4-807b-1f39191afcc7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator</th>\n",
       "      <th>argumentative</th>\n",
       "      <th>overall quality</th>\n",
       "      <th>local acceptability</th>\n",
       "      <th>appropriateness</th>\n",
       "      <th>arrangement</th>\n",
       "      <th>clarity</th>\n",
       "      <th>cogency</th>\n",
       "      <th>effectiveness</th>\n",
       "      <th>global acceptability</th>\n",
       "      <th>...</th>\n",
       "      <th>global sufficiency</th>\n",
       "      <th>reasonableness</th>\n",
       "      <th>local relevance</th>\n",
       "      <th>credibility</th>\n",
       "      <th>emotional appeal</th>\n",
       "      <th>sufficiency</th>\n",
       "      <th>argument</th>\n",
       "      <th>#id</th>\n",
       "      <th>issue</th>\n",
       "      <th>stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>1</td>\n",
       "      <td>y</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>...</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>3 (High)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>\"Debates are based on convincing evidence. The...</td>\n",
       "      <td>28068</td>\n",
       "      <td>evolution-vs-creation</td>\n",
       "      <td>creation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2</td>\n",
       "      <td>y</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>3 (High)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>...</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>\"Debates are based on convincing evidence. The...</td>\n",
       "      <td>28068</td>\n",
       "      <td>evolution-vs-creation</td>\n",
       "      <td>creation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>3</td>\n",
       "      <td>y</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>3 (High)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>...</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>\"Debates are based on convincing evidence. The...</td>\n",
       "      <td>28068</td>\n",
       "      <td>evolution-vs-creation</td>\n",
       "      <td>creation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     annotator argumentative overall quality local acceptability  \\\n",
       "144          1             y     2 (Average)         2 (Average)   \n",
       "145          2             y         1 (Low)             1 (Low)   \n",
       "146          3             y     2 (Average)         2 (Average)   \n",
       "\n",
       "    appropriateness  arrangement      clarity      cogency effectiveness  \\\n",
       "144     2 (Average)  2 (Average)  2 (Average)      1 (Low)       1 (Low)   \n",
       "145        3 (High)  2 (Average)  2 (Average)      1 (Low)       1 (Low)   \n",
       "146     2 (Average)  2 (Average)     3 (High)  2 (Average)       1 (Low)   \n",
       "\n",
       "    global acceptability  ... global sufficiency reasonableness  \\\n",
       "144              1 (Low)  ...            1 (Low)        1 (Low)   \n",
       "145              1 (Low)  ...            1 (Low)        1 (Low)   \n",
       "146          2 (Average)  ...            1 (Low)        1 (Low)   \n",
       "\n",
       "    local relevance credibility emotional appeal  sufficiency  \\\n",
       "144        3 (High)     1 (Low)      2 (Average)      1 (Low)   \n",
       "145     2 (Average)     1 (Low)      2 (Average)      1 (Low)   \n",
       "146     2 (Average)     1 (Low)      2 (Average)  2 (Average)   \n",
       "\n",
       "                                              argument    #id  \\\n",
       "144  \"Debates are based on convincing evidence. The...  28068   \n",
       "145  \"Debates are based on convincing evidence. The...  28068   \n",
       "146  \"Debates are based on convincing evidence. The...  28068   \n",
       "\n",
       "                     issue    stance  \n",
       "144  evolution-vs-creation  creation  \n",
       "145  evolution-vs-creation  creation  \n",
       "146  evolution-vs-creation  creation  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"#id\"] == \"28068\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9bb9243",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "b9bb9243",
    "outputId": "6129a267-3518-4536-bb21-d5ee253ca74d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#id</th>\n",
       "      <th>argument</th>\n",
       "      <th>overall quality</th>\n",
       "      <th>cogency</th>\n",
       "      <th>effectiveness</th>\n",
       "      <th>reasonableness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28068</td>\n",
       "      <td>\"Debates are based on convincing evidence. The...</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13270</td>\n",
       "      <td>\"If a women is raped\" is a good argument. Howe...</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13275</td>\n",
       "      <td>\"The government has no place to tell a woman w...</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12365</td>\n",
       "      <td>(I am writing this through Firefox) Emotions a...</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>2 (Average)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arg561672</td>\n",
       "      <td>1. It makes everyone equal - if children can w...</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>2 (Average)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>arg334959</td>\n",
       "      <td>yea, because even though there are many other ...</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>2 (Average)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>arg335089</td>\n",
       "      <td>yes because if they fear getting hit than they...</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>arg203922</td>\n",
       "      <td>yes, i believe it's nice to have a school unif...</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>2 (Average)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>2 (Average)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>arg596217</td>\n",
       "      <td>yes,India has potential to lead the world.So, ...</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>arg399268</td>\n",
       "      <td>you can get the \"Foxtel Go\" app on your Ipad s...</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "      <td>1 (Low)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           #id                                           argument  \\\n",
       "0        28068  \"Debates are based on convincing evidence. The...   \n",
       "1        13270  \"If a women is raped\" is a good argument. Howe...   \n",
       "2        13275  \"The government has no place to tell a woman w...   \n",
       "3        12365  (I am writing this through Firefox) Emotions a...   \n",
       "4    arg561672  1. It makes everyone equal - if children can w...   \n",
       "..         ...                                                ...   \n",
       "256  arg334959  yea, because even though there are many other ...   \n",
       "257  arg335089  yes because if they fear getting hit than they...   \n",
       "258  arg203922  yes, i believe it's nice to have a school unif...   \n",
       "259  arg596217  yes,India has potential to lead the world.So, ...   \n",
       "260  arg399268  you can get the \"Foxtel Go\" app on your Ipad s...   \n",
       "\n",
       "    overall quality      cogency effectiveness reasonableness  \n",
       "0       2 (Average)      1 (Low)       1 (Low)        1 (Low)  \n",
       "1           1 (Low)      1 (Low)       1 (Low)        1 (Low)  \n",
       "2           1 (Low)      1 (Low)       1 (Low)        1 (Low)  \n",
       "3       2 (Average)      1 (Low)       1 (Low)    2 (Average)  \n",
       "4           1 (Low)  2 (Average)       1 (Low)    2 (Average)  \n",
       "..              ...          ...           ...            ...  \n",
       "256     2 (Average)  2 (Average)       1 (Low)    2 (Average)  \n",
       "257         1 (Low)      1 (Low)       1 (Low)        1 (Low)  \n",
       "258     2 (Average)  2 (Average)       1 (Low)    2 (Average)  \n",
       "259         1 (Low)      1 (Low)       1 (Low)        1 (Low)  \n",
       "260         1 (Low)      1 (Low)       1 (Low)        1 (Low)  \n",
       "\n",
       "[261 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8d53f2e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b8d53f2e",
    "outputId": "8df549c0-cb0a-4fde-b39e-4a9207b937d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of arguements = 261\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of arguements = {len(cleaned_df['argument'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c787103",
   "metadata": {
    "id": "9c787103",
    "tags": []
   },
   "source": [
    "### **DATA PREPROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc953023",
   "metadata": {
    "id": "cc953023"
   },
   "outputs": [],
   "source": [
    "text = cleaned_df[\"argument\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f73a3bb1",
   "metadata": {
    "id": "f73a3bb1"
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "english_stopwords = stopwords.words(\"english\")\n",
    "english_stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1930ac95",
   "metadata": {
    "id": "1930ac95"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace('</br>', '') # Remove </br>\n",
    "    text = re.sub(r'[^\\w]', ' ', text) # Remove symbols\n",
    "    text = re.sub(r'[ ]{2,}', ' ', text) # Remove extra spaces\n",
    "    text = re.sub(r'[ \\t]+$', '', text) # Remove trailing white spaces\n",
    "    tokens = []\n",
    "    for token in text.split():\n",
    "        if token not in stop_words:\n",
    "            token = english_stemmer.stem(token)\n",
    "            tokens.append(token)\n",
    "    return \" \".join(tokens)\n",
    "    #return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "805b7956",
   "metadata": {
    "id": "805b7956"
   },
   "outputs": [],
   "source": [
    "cleaned_text = [clean_text(text) for text in text]\n",
    "text = cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa24e34",
   "metadata": {
    "id": "8fa24e34"
   },
   "source": [
    "### **VECTORIZE THE TEXT DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b9c0294",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b9c0294",
    "outputId": "8c249f99-fb3b-47e9-ad7d-750eae84c19f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Vector = (261, 2001)\n"
     ]
    }
   ],
   "source": [
    "# Using Bag of Words (BoW)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(text)\n",
    "X = X.toarray()\n",
    "\n",
    "print(f\"Shape of Vector = {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d40667",
   "metadata": {
    "id": "79d40667"
   },
   "source": [
    "### **PREDICTING COGENCY FROM TEXT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81744c3a",
   "metadata": {
    "id": "81744c3a"
   },
   "outputs": [],
   "source": [
    "y = cleaned_df[\"cogency\"].to_numpy()\n",
    "# y = y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c869c9",
   "metadata": {
    "id": "86c869c9"
   },
   "source": [
    "#### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db885c8c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db885c8c",
    "outputId": "b50c70a6-2662-4b70-ee6f-39f0feb1583e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Labels = (261,)\n"
     ]
    }
   ],
   "source": [
    "# Label Encoding\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "enc_y = encoder.fit_transform(y)\n",
    "y = enc_y\n",
    "\n",
    "print(f\"Size of Labels = {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "354c58ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "354c58ee",
    "outputId": "000a5f65-f052-49ad-d328-ee93bd70eeac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training Data: (261, 2001)\n",
      "Shape of Training Labels: (261,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of Training Data: {X.shape}\")\n",
    "print(f\"Shape of Training Labels: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04a2a2a",
   "metadata": {
    "id": "a04a2a2a"
   },
   "source": [
    "#### Training Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a1427ef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7a1427ef",
    "outputId": "e1a3913a-8332-4e13-dfd3-0fc401c117f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.77      0.69       147\n",
      "           1       0.49      0.40      0.44        97\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.58       261\n",
      "   macro avg       0.37      0.39      0.38       261\n",
      "weighted avg       0.53      0.58      0.55       261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(dual=False, fit_intercept=True, penalty=\"none\", solver=\"sag\", max_iter=5000)\n",
    "pred = cross_val_predict(model, X, y, cv=5)\n",
    "print(classification_report(y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RseqU6faq5pi",
   "metadata": {
    "id": "RseqU6faq5pi"
   },
   "source": [
    "#### Training Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "DXrPmO98pPKV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DXrPmO98pPKV",
    "outputId": "c44a740b-8064-46db-c26d-025d409a4df2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.71      0.64       147\n",
      "           1       0.38      0.28      0.32        97\n",
      "           2       0.25      0.12      0.16        17\n",
      "\n",
      "    accuracy                           0.51       261\n",
      "   macro avg       0.40      0.37      0.37       261\n",
      "weighted avg       0.48      0.51      0.49       261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(criterion=\"gini\", max_features=\"log2\", splitter=\"best\")\n",
    "pred = cross_val_predict(model, X, y, cv=5)\n",
    "print(classification_report(y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "r0BTjsVosj_5",
   "metadata": {
    "id": "r0BTjsVosj_5"
   },
   "source": [
    "#### Training Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "BOotuIJFsA-a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BOotuIJFsA-a",
    "outputId": "3c11c5b0-557d-494f-9d29-8b614b68a9fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.78      0.69       147\n",
      "           1       0.44      0.33      0.38        97\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.56       261\n",
      "   macro avg       0.35      0.37      0.36       261\n",
      "weighted avg       0.51      0.56      0.53       261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(bootstrap=True, class_weight='balanced', \n",
    "    criterion='gini', max_features=None, n_estimators=300, oob_score=False, warm_start=False)\n",
    "pred = cross_val_predict(model, X, y, cv=5)\n",
    "print(classification_report(y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f845756e",
   "metadata": {
    "id": "f845756e"
   },
   "source": [
    "#### Training Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "942a9262",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "942a9262",
    "outputId": "bc7e487d-2267-4821-c2e2-efdaf2464dbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Labels = (261, 3)\n",
      "Label Sample: [1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# One Hot Encoding\n",
    "\n",
    "y = cleaned_df[\"cogency\"].to_numpy()\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "enc_y = encoder.fit_transform(y)\n",
    "y = enc_y.toarray()\n",
    "\n",
    "print(f\"Size of Labels = {y.shape}\")\n",
    "print(f\"Label Sample: {y[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "41a23d0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41a23d0a",
    "outputId": "420d21f5-e677-4f7f-da7c-94befdf8ab83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training Data: (261, 2001)\n",
      "Shape of Training Labels: (261, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of Training Data: {X.shape}\")\n",
    "print(f\"Shape of Training Labels: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cb0a8b7f",
   "metadata": {
    "id": "cb0a8b7f"
   },
   "outputs": [],
   "source": [
    "def init_model():\n",
    "\n",
    "    # Define Model\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Dense(32, input_dim=X.shape[1], activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.6),\n",
    "        keras.layers.Dense(128, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.6),\n",
    "        keras.layers.Dense(64, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(3, activation=\"softmax\"),\n",
    "    ])\n",
    "\n",
    "    loss_function = keras.losses.CategoricalCrossentropy() # Define loss function\n",
    "    # loss_function = keras.losses.SparseCategoricalCrossentropy() # Define loss function\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=0.005) # Define optimizer\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss_function, metrics=[\"accuracy\"]) # Compile the model\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "298af456",
   "metadata": {
    "id": "298af456"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f71b011eef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "pred = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    model = init_model()\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs=75, batch_size=1, \n",
    "        validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "    pred_test = [np.argmax(ele) for ele in model.predict(X_test)]\n",
    "    pred += pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "48b85069",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48b85069",
    "outputId": "e94944aa-a897-4808-d3a7-ca204006a8eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.71      0.68       147\n",
      "           1       0.48      0.48      0.48        97\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.58       261\n",
      "   macro avg       0.38      0.40      0.39       261\n",
      "weighted avg       0.55      0.58      0.56       261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_y = [np.argmax(ele) for ele in y]\n",
    "print(classification_report(new_y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oPg7YD-cByNv",
   "metadata": {
    "id": "oPg7YD-cByNv"
   },
   "source": [
    "### **PREDICTING EFFECTIVENESS FROM TEXT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9CvshYYeByNw",
   "metadata": {
    "id": "9CvshYYeByNw"
   },
   "outputs": [],
   "source": [
    "y = cleaned_df[\"effectiveness\"].to_numpy()\n",
    "# y = y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7yiTMCBWByNw",
   "metadata": {
    "id": "7yiTMCBWByNw"
   },
   "source": [
    "#### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6GECJuHOByNw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6GECJuHOByNw",
    "outputId": "b50c70a6-2662-4b70-ee6f-39f0feb1583e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Labels = (261,)\n"
     ]
    }
   ],
   "source": [
    "# Label Encoding\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "enc_y = encoder.fit_transform(y)\n",
    "y = enc_y\n",
    "\n",
    "print(f\"Size of Labels = {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bCULYMMNByNx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bCULYMMNByNx",
    "outputId": "000a5f65-f052-49ad-d328-ee93bd70eeac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training Data: (261, 2001)\n",
      "Shape of Training Labels: (261,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of Training Data: {X.shape}\")\n",
    "print(f\"Shape of Training Labels: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "COYxRNYzByNx",
   "metadata": {
    "id": "COYxRNYzByNx"
   },
   "source": [
    "#### Training Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "IJYZWvgsByNx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IJYZWvgsByNx",
    "outputId": "e1a3913a-8332-4e13-dfd3-0fc401c117f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.80      0.73       172\n",
      "           1       0.33      0.23      0.27        80\n",
      "           2       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.60       261\n",
      "   macro avg       0.33      0.34      0.33       261\n",
      "weighted avg       0.54      0.60      0.56       261\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sri/Documents/UTS Research/explainable-ai-in-learning-analytics/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sri/Documents/UTS Research/explainable-ai-in-learning-analytics/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sri/Documents/UTS Research/explainable-ai-in-learning-analytics/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(dual=False, fit_intercept=True, penalty=\"none\", solver=\"sag\", max_iter=5000)\n",
    "pred = cross_val_predict(model, X, y, cv=5)\n",
    "print(classification_report(y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y3OMVsL6ByNy",
   "metadata": {
    "id": "y3OMVsL6ByNy"
   },
   "source": [
    "#### Training Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "WM7wltZiByNy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WM7wltZiByNy",
    "outputId": "c44a740b-8064-46db-c26d-025d409a4df2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.77      0.71       172\n",
      "           1       0.33      0.23      0.27        80\n",
      "           2       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.58       261\n",
      "   macro avg       0.33      0.33      0.33       261\n",
      "weighted avg       0.54      0.58      0.55       261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(criterion=\"gini\", max_features=\"log2\", splitter=\"best\")\n",
    "pred = cross_val_predict(model, X, y, cv=5)\n",
    "print(classification_report(y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q0NjxmXDByNz",
   "metadata": {
    "id": "q0NjxmXDByNz"
   },
   "source": [
    "#### Training Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7svcFHIyByNz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7svcFHIyByNz",
    "outputId": "3c11c5b0-557d-494f-9d29-8b614b68a9fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.88      0.77       172\n",
      "           1       0.43      0.20      0.27        80\n",
      "           2       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.64       261\n",
      "   macro avg       0.37      0.36      0.35       261\n",
      "weighted avg       0.58      0.64      0.59       261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(bootstrap=True, class_weight='balanced', \n",
    "    criterion='gini', max_features=None, n_estimators=300, oob_score=False, warm_start=False)\n",
    "pred = cross_val_predict(model, X, y, cv=5)\n",
    "print(classification_report(y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84OOdXF-ByN0",
   "metadata": {
    "id": "84OOdXF-ByN0"
   },
   "source": [
    "#### Training Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "YpM2EvF0ByN1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YpM2EvF0ByN1",
    "outputId": "bc7e487d-2267-4821-c2e2-efdaf2464dbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Labels = (261, 3)\n",
      "Label Sample: [1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# One Hot Encoding\n",
    "\n",
    "y = cleaned_df[\"effectiveness\"].to_numpy()\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "enc_y = encoder.fit_transform(y)\n",
    "y = enc_y.toarray()\n",
    "\n",
    "print(f\"Size of Labels = {y.shape}\")\n",
    "print(f\"Label Sample: {y[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "DoXJbmkXByN1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DoXJbmkXByN1",
    "outputId": "420d21f5-e677-4f7f-da7c-94befdf8ab83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training Data: (261, 2001)\n",
      "Shape of Training Labels: (261, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of Training Data: {X.shape}\")\n",
    "print(f\"Shape of Training Labels: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "LKDG51oLByN2",
   "metadata": {
    "id": "LKDG51oLByN2"
   },
   "outputs": [],
   "source": [
    "def init_model():\n",
    "\n",
    "    # Define Model\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Dense(32, input_dim=X.shape[1], activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.6),\n",
    "        keras.layers.Dense(128, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.6),\n",
    "        keras.layers.Dense(64, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(3, activation=\"softmax\"),\n",
    "    ])\n",
    "\n",
    "    loss_function = keras.losses.CategoricalCrossentropy() # Define loss function\n",
    "    # loss_function = keras.losses.SparseCategoricalCrossentropy() # Define loss function\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=0.005) # Define optimizer\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss_function, metrics=[\"accuracy\"]) # Compile the model\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "Q9d9R3SzByN2",
   "metadata": {
    "id": "Q9d9R3SzByN2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "pred = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    model = init_model()\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs=75, batch_size=1, \n",
    "        validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "    pred_test = [np.argmax(ele) for ele in model.predict(X_test)]\n",
    "    pred += pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "N6_hR9b7ByN3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N6_hR9b7ByN3",
    "outputId": "e94944aa-a897-4808-d3a7-ca204006a8eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.78      0.72       172\n",
      "           1       0.34      0.25      0.29        80\n",
      "           2       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.59       261\n",
      "   macro avg       0.34      0.34      0.34       261\n",
      "weighted avg       0.54      0.59      0.56       261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_y = [np.argmax(ele) for ele in y]\n",
    "print(classification_report(new_y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "X_Of2RuFByN3",
   "metadata": {
    "id": "X_Of2RuFByN3"
   },
   "source": [
    "### **PREDICTING REASONABLENESS FROM TEXT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "PW0uuCDNByN3",
   "metadata": {
    "id": "PW0uuCDNByN3"
   },
   "outputs": [],
   "source": [
    "y = cleaned_df[\"reasonableness\"].to_numpy()\n",
    "# y = y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SFT_COapByN4",
   "metadata": {
    "id": "SFT_COapByN4"
   },
   "source": [
    "#### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "MJRKlOvsByN4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MJRKlOvsByN4",
    "outputId": "b50c70a6-2662-4b70-ee6f-39f0feb1583e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Labels = (261,)\n"
     ]
    }
   ],
   "source": [
    "# Label Encoding\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "enc_y = encoder.fit_transform(y)\n",
    "y = enc_y\n",
    "\n",
    "print(f\"Size of Labels = {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-v_ET4ExByN4",
   "metadata": {
    "id": "-v_ET4ExByN4"
   },
   "source": [
    "#### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "tenW3tyzByN4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tenW3tyzByN4",
    "outputId": "000a5f65-f052-49ad-d328-ee93bd70eeac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training Data: (261, 2001)\n",
      "Shape of Training Labels: (261,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of Training Data: {X.shape}\")\n",
    "print(f\"Shape of Training Labels: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HoCcYqfXByN5",
   "metadata": {
    "id": "HoCcYqfXByN5"
   },
   "source": [
    "#### Training Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "pIjYGqZ8ByN5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pIjYGqZ8ByN5",
    "outputId": "e1a3913a-8332-4e13-dfd3-0fc401c117f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.64      0.59       124\n",
      "           1       0.54      0.50      0.51       123\n",
      "           2       0.00      0.00      0.00        14\n",
      "\n",
      "    accuracy                           0.54       261\n",
      "   macro avg       0.36      0.38      0.37       261\n",
      "weighted avg       0.51      0.54      0.52       261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(dual=False, fit_intercept=True, penalty=\"none\", solver=\"sag\", max_iter=5000)\n",
    "pred = cross_val_predict(model, X, y, cv=5)\n",
    "print(classification_report(y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9W7GrISMByN6",
   "metadata": {
    "id": "9W7GrISMByN6"
   },
   "source": [
    "#### Training Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d46ffMjfByN6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d46ffMjfByN6",
    "outputId": "c44a740b-8064-46db-c26d-025d409a4df2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.67      0.59       124\n",
      "           1       0.58      0.46      0.51       123\n",
      "           2       0.00      0.00      0.00        14\n",
      "\n",
      "    accuracy                           0.53       261\n",
      "   macro avg       0.37      0.37      0.37       261\n",
      "weighted avg       0.53      0.53      0.52       261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(criterion=\"gini\", max_features=\"log2\", splitter=\"best\")\n",
    "pred = cross_val_predict(model, X, y, cv=5)\n",
    "print(classification_report(y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LxEmoIT9ByN7",
   "metadata": {
    "id": "LxEmoIT9ByN7"
   },
   "source": [
    "#### Training Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0xLLXvTUByN8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0xLLXvTUByN8",
    "outputId": "3c11c5b0-557d-494f-9d29-8b614b68a9fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.67      0.59       124\n",
      "           1       0.52      0.43      0.47       123\n",
      "           2       0.00      0.00      0.00        14\n",
      "\n",
      "    accuracy                           0.52       261\n",
      "   macro avg       0.35      0.37      0.35       261\n",
      "weighted avg       0.50      0.52      0.50       261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(bootstrap=True, class_weight='balanced', \n",
    "    criterion='gini', max_features=None, n_estimators=300, oob_score=False, warm_start=False)\n",
    "pred = cross_val_predict(model, X, y, cv=5)\n",
    "print(classification_report(y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IXoAhJCqByN-",
   "metadata": {
    "id": "IXoAhJCqByN-"
   },
   "source": [
    "#### Training Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "zALmqqqqByN-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zALmqqqqByN-",
    "outputId": "bc7e487d-2267-4821-c2e2-efdaf2464dbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Labels = (261, 3)\n",
      "Label Sample: [1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# One Hot Encoding\n",
    "\n",
    "y = cleaned_df[\"reasonableness\"].to_numpy()\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "enc_y = encoder.fit_transform(y)\n",
    "y = enc_y.toarray()\n",
    "\n",
    "print(f\"Size of Labels = {y.shape}\")\n",
    "print(f\"Label Sample: {y[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bUNn5_U0ByN_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bUNn5_U0ByN_",
    "outputId": "420d21f5-e677-4f7f-da7c-94befdf8ab83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training Data: (261, 2001)\n",
      "Shape of Training Labels: (261, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of Training Data: {X.shape}\")\n",
    "print(f\"Shape of Training Labels: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "pbm-SGbvByN_",
   "metadata": {
    "id": "pbm-SGbvByN_"
   },
   "outputs": [],
   "source": [
    "def init_model():\n",
    "\n",
    "    # Define Model\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Dense(32, input_dim=X.shape[1], activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.6),\n",
    "        keras.layers.Dense(128, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.6),\n",
    "        keras.layers.Dense(64, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(3, activation=\"softmax\"),\n",
    "    ])\n",
    "\n",
    "    loss_function = keras.losses.CategoricalCrossentropy() # Define loss function\n",
    "    # loss_function = keras.losses.SparseCategoricalCrossentropy() # Define loss function\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=0.005) # Define optimizer\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss_function, metrics=[\"accuracy\"]) # Compile the model\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ubsn2MjoByOA",
   "metadata": {
    "id": "ubsn2MjoByOA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "pred = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    model = init_model()\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs=75, batch_size=1, \n",
    "        validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "    pred_test = [np.argmax(ele) for ele in model.predict(X_test)]\n",
    "    pred += pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b511bfeb",
   "metadata": {
    "id": "b511bfeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.63      0.60       124\n",
      "           1       0.58      0.59      0.59       123\n",
      "           2       0.00      0.00      0.00        14\n",
      "\n",
      "    accuracy                           0.58       261\n",
      "   macro avg       0.39      0.41      0.40       261\n",
      "weighted avg       0.55      0.58      0.56       261\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sri/Documents/UTS Research/explainable-ai-in-learning-analytics/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sri/Documents/UTS Research/explainable-ai-in-learning-analytics/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sri/Documents/UTS Research/explainable-ai-in-learning-analytics/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "new_y = [np.argmax(ele) for ele in y]\n",
    "print(classification_report(new_y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PcgPtowxByOB",
   "metadata": {
    "id": "PcgPtowxByOB"
   },
   "source": [
    "### **PREDICTING OVERALL QUALITY FROM TEXT + ATTRIBUTES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "YYwhXtt4ByOB",
   "metadata": {
    "id": "YYwhXtt4ByOB"
   },
   "outputs": [],
   "source": [
    "y = cleaned_df[\"overall quality\"].to_numpy()\n",
    "# y = y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5803879",
   "metadata": {
    "id": "b5803879"
   },
   "source": [
    "#### Adding the Attributes to Argument Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "T94yqkiGD2i6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T94yqkiGD2i6",
    "outputId": "52819df7-3723-46be-dcc0-7859d1fd4772"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape of Vector = (261, 2001)\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the Arguments\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(text)\n",
    "X = X.toarray()\n",
    "\n",
    "print(f\"Initial shape of Vector = {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ZN88xx1bCbSg",
   "metadata": {
    "id": "ZN88xx1bCbSg"
   },
   "outputs": [],
   "source": [
    "attr_enc_map = {\n",
    "    \"1 (Low)\": np.array([0, 0, 1]),\n",
    "    \"2 (Average)\": np.array([0, 1, 0]),\n",
    "    \"3 (High)\": np.array([1, 0, 0]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dA7Uss1UCdB_",
   "metadata": {
    "id": "dA7Uss1UCdB_"
   },
   "outputs": [],
   "source": [
    "def encode(array):\n",
    "    temp_list = []\n",
    "    for ele in array:\n",
    "        temp_list.append(attr_enc_map[ele])\n",
    "    return np.array(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "JSjuZl19CT5T",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JSjuZl19CT5T",
    "outputId": "a7bb80dc-a6e0-43a7-9096-6a0650d9b65a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape of Vector = (261, 2010)\n"
     ]
    }
   ],
   "source": [
    "cogency = cleaned_df[\"cogency\"].to_numpy()\n",
    "effectiveness = cleaned_df[\"effectiveness\"].to_numpy()\n",
    "reasonableness = cleaned_df[\"reasonableness\"].to_numpy()\n",
    "\n",
    "cogency = encode(cogency)\n",
    "effectiveness = encode(effectiveness)\n",
    "reasonableness = encode(reasonableness)\n",
    "\n",
    "X_new = []\n",
    "\n",
    "for idx, x in enumerate(X):\n",
    "    temp = np.concatenate((cogency[idx], effectiveness[idx], reasonableness[idx], x))\n",
    "    X_new.append(temp)\n",
    "\n",
    "X = np.array(X_new)\n",
    "\n",
    "print(f\"Final shape of Vector = {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Dga8JdxzByOB",
   "metadata": {
    "id": "Dga8JdxzByOB"
   },
   "source": [
    "#### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "KS5QHbVLByOC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KS5QHbVLByOC",
    "outputId": "918b3e43-9090-47fd-e45f-a451ed0e73df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Labels = (261,)\n"
     ]
    }
   ],
   "source": [
    "# Label Encoding\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "enc_y = encoder.fit_transform(y)\n",
    "y = enc_y\n",
    "\n",
    "print(f\"Size of Labels = {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i0YN_rBvByOC",
   "metadata": {
    "id": "i0YN_rBvByOC"
   },
   "source": [
    "#### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bHLQKPp1ByOC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bHLQKPp1ByOC",
    "outputId": "5aa72e2e-fa3e-4edb-dea1-f833c165d515"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training Data: (261, 2010)\n",
      "Shape of Training Labels: (261,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of Training Data: {X.shape}\")\n",
    "print(f\"Shape of Training Labels: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cVQVTWCqByOC",
   "metadata": {
    "id": "cVQVTWCqByOC"
   },
   "source": [
    "#### Training Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "rkw4xB8BByOD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rkw4xB8BByOD",
    "outputId": "a6117b93-8798-4eda-add4-06b64ee09a88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92       149\n",
      "           1       0.81      0.85      0.83        96\n",
      "           2       1.00      0.19      0.32        16\n",
      "\n",
      "    accuracy                           0.86       261\n",
      "   macro avg       0.90      0.66      0.69       261\n",
      "weighted avg       0.87      0.86      0.85       261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C=0.1, dual=False, fit_intercept=True, penalty=\"l2\", solver=\"newton-cg\")\n",
    "pred = cross_val_predict(model, X, y, cv=5)\n",
    "print(classification_report(y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hSCiRIUCByOD",
   "metadata": {
    "id": "hSCiRIUCByOD"
   },
   "source": [
    "#### Training Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "krIdWtklByOE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "krIdWtklByOE",
    "outputId": "5b526532-8b43-4733-b583-bd5d34273a82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86       149\n",
      "           1       0.81      0.70      0.75        96\n",
      "           2       0.79      0.69      0.73        16\n",
      "\n",
      "    accuracy                           0.82       261\n",
      "   macro avg       0.81      0.76      0.78       261\n",
      "weighted avg       0.82      0.82      0.81       261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(criterion=\"entropy\", max_features=\"sqrt\", splitter=\"best\")\n",
    "pred = cross_val_predict(model, X, y, cv=5)\n",
    "print(classification_report(y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z3Rhxg_AByOF",
   "metadata": {
    "id": "z3Rhxg_AByOF"
   },
   "source": [
    "#### Training Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "CFOJXqfSByOG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CFOJXqfSByOG",
    "outputId": "00a134c2-30a2-47a9-8870-0e24df9e4f23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90       149\n",
      "           1       0.80      0.84      0.82        96\n",
      "           2       0.78      0.88      0.82        16\n",
      "\n",
      "    accuracy                           0.87       261\n",
      "   macro avg       0.83      0.87      0.85       261\n",
      "weighted avg       0.87      0.87      0.87       261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(bootstrap=True, class_weight='balanced', \n",
    "    criterion='gini', max_features=None, n_estimators=300, oob_score=False, warm_start=False)\n",
    "pred = cross_val_predict(model, X, y, cv=5)\n",
    "pred = cross_val_predict(model, X, y, cv=5)\n",
    "print(classification_report(y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PWUm6cgtByOH",
   "metadata": {
    "id": "PWUm6cgtByOH"
   },
   "source": [
    "#### Training Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "GDRmqFVvByOH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GDRmqFVvByOH",
    "outputId": "61eb16bb-4e69-4c4f-d92f-a698d30f3891"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Labels = (261, 3)\n",
      "Label Sample: [0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "# One Hot Encoding\n",
    "\n",
    "y = cleaned_df[\"overall quality\"].to_numpy()\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "enc_y = encoder.fit_transform(y)\n",
    "y = enc_y.toarray()\n",
    "\n",
    "print(f\"Size of Labels = {y.shape}\")\n",
    "print(f\"Label Sample: {y[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1cKvwwzFByOI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1cKvwwzFByOI",
    "outputId": "a674552a-a03a-4e89-ef4e-d39a2070bab3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training Data: (261, 2010)\n",
      "Shape of Training Labels: (261, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of Training Data: {X.shape}\")\n",
    "print(f\"Shape of Training Labels: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "vujrjILqByOK",
   "metadata": {
    "id": "vujrjILqByOK"
   },
   "outputs": [],
   "source": [
    "def init_model():\n",
    "\n",
    "    # Define Model\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Dense(32, input_dim=X.shape[1], activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.6),\n",
    "        keras.layers.Dense(128, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.6),\n",
    "        keras.layers.Dense(64, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(3, activation=\"softmax\"),\n",
    "    ])\n",
    "\n",
    "    loss_function = keras.losses.CategoricalCrossentropy() # Define loss function\n",
    "    # loss_function = keras.losses.SparseCategoricalCrossentropy() # Define loss function\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=0.005) # Define optimizer\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss_function, metrics=[\"accuracy\"]) # Compile the model\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "R4mT1lfCByOK",
   "metadata": {
    "id": "R4mT1lfCByOK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "pred = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    model = init_model()\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs=75, batch_size=1, \n",
    "        validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "    pred_test = [np.argmax(ele) for ele in model.predict(X_test)]\n",
    "    pred += pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e_O_49Z3ByOL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e_O_49Z3ByOL",
    "outputId": "7aa5d807-4f64-4314-ebaf-2d4a909ff471"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       149\n",
      "           1       0.83      0.89      0.85        96\n",
      "           2       0.83      0.31      0.45        16\n",
      "\n",
      "    accuracy                           0.87       261\n",
      "   macro avg       0.86      0.71      0.74       261\n",
      "weighted avg       0.87      0.87      0.87       261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_y = [np.argmax(ele) for ele in y]\n",
    "print(classification_report(new_y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p8950BwCFKOJ",
   "metadata": {
    "id": "p8950BwCFKOJ"
   },
   "source": [
    "### **BUILDING THE 2-LAYER MODEL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Wb85XU6sFRTO",
   "metadata": {
    "id": "Wb85XU6sFRTO"
   },
   "source": [
    "#### Neural Network to Predict the Cogency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "O8HUge_dByOL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "id": "O8HUge_dByOL",
    "outputId": "5848709c-d8be-4f0c-fcaf-9687d76b4ade"
   },
   "outputs": [],
   "source": [
    "# Vectorize the Arguments\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(text)\n",
    "X = X.toarray()\n",
    "\n",
    "# Extract Cogency\n",
    "y = cleaned_df[\"cogency\"].to_numpy()\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "# Label Encoding\n",
    "encoder = OneHotEncoder()\n",
    "enc_y = encoder.fit_transform(y)\n",
    "enc_y = enc_y.toarray()\n",
    "\n",
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, enc_y, test_size=0.2, random_state=110)\n",
    "\n",
    "# Define Custom Callback\n",
    "class MyThresholdCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, threshold):\n",
    "        super(MyThresholdCallback, self).__init__()\n",
    "        self.threshold = threshold\n",
    "    def on_epoch_end(self, epoch, logs=None): \n",
    "        val_acc = logs[\"val_accuracy\"]\n",
    "        if val_acc >= self.threshold:\n",
    "            self.model.stop_training = True\n",
    "\n",
    "# Define Model\n",
    "cog_model = keras.models.Sequential([\n",
    "    keras.layers.Dense(32, input_dim=X_train.shape[1], activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.6),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.6),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(3, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "# Define Parameters\n",
    "loss_function = keras.losses.CategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.005)\n",
    "callback = MyThresholdCallback(threshold=0.66)\n",
    "\n",
    "# Compile Model\n",
    "cog_model.compile(optimizer=optimizer, loss=loss_function, metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "history = cog_model.fit(X_train, y_train, epochs=1000, batch_size=1, \n",
    "    validation_data=(X_test, y_test), callbacks=[callback], verbose=0)\n",
    "\n",
    "# Print Validation Accurace of Model\n",
    "print(f\"Validation Accuracy of Model = {cog_model.evaluate(X_test, y_test, verbose=0)[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KF7WYplzIIO2",
   "metadata": {
    "id": "KF7WYplzIIO2"
   },
   "source": [
    "#### Neural Network to Predict the Effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ihpfmnLmHmYV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ihpfmnLmHmYV",
    "outputId": "4c5a98c4-9249-4bd6-9ffa-2ae44f4526b9"
   },
   "outputs": [],
   "source": [
    "# Vectorize the Arguments\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(text)\n",
    "X = X.toarray()\n",
    "\n",
    "# Extract Effectiveness\n",
    "y = cleaned_df[\"effectiveness\"].to_numpy()\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "# Label Encoding\n",
    "encoder = OneHotEncoder()\n",
    "enc_y = encoder.fit_transform(y)\n",
    "enc_y = enc_y.toarray()\n",
    "\n",
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, enc_y, test_size=0.2, random_state=110)\n",
    "\n",
    "# Define Custom Callback\n",
    "class MyThresholdCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, threshold):\n",
    "        super(MyThresholdCallback, self).__init__()\n",
    "        self.threshold = threshold\n",
    "    def on_epoch_end(self, epoch, logs=None): \n",
    "        val_acc = logs[\"val_accuracy\"]\n",
    "        if val_acc >= self.threshold:\n",
    "            self.model.stop_training = True\n",
    "\n",
    "# Define Model\n",
    "eff_model = keras.models.Sequential([\n",
    "    keras.layers.Dense(32, input_dim=X_train.shape[1], activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.6),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.6),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(3, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "# Define Parameters\n",
    "loss_function = keras.losses.CategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.005)\n",
    "callback = MyThresholdCallback(threshold=0.66)\n",
    "\n",
    "# Compile Model\n",
    "eff_model.compile(optimizer=optimizer, loss=loss_function, metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "history = eff_model.fit(X_train, y_train, epochs=1000, batch_size=1, \n",
    "    validation_data=(X_test, y_test), callbacks=[callback], verbose=0)\n",
    "\n",
    "# Print Validation Accurace of Model\n",
    "print(f\"Validation Accuracy of Model = {eff_model.evaluate(X_test, y_test, verbose=0)[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc2af39",
   "metadata": {},
   "source": [
    "#### Neural Network to Predict the Reasonableness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MJ3iHUaBIXit",
   "metadata": {
    "id": "MJ3iHUaBIXit"
   },
   "outputs": [],
   "source": [
    "# Vectorize the Arguments\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(text)\n",
    "X = X.toarray()\n",
    "\n",
    "# Extract Reasonableness\n",
    "y = cleaned_df[\"reasonableness\"].to_numpy()\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "# Label Encoding\n",
    "encoder = OneHotEncoder()\n",
    "enc_y = encoder.fit_transform(y)\n",
    "enc_y = enc_y.toarray()\n",
    "\n",
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, enc_y, test_size=0.2, random_state=110)\n",
    "\n",
    "# Define Custom Callback\n",
    "class MyThresholdCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, threshold):\n",
    "        super(MyThresholdCallback, self).__init__()\n",
    "        self.threshold = threshold\n",
    "    def on_epoch_end(self, epoch, logs=None): \n",
    "        val_acc = logs[\"val_accuracy\"]\n",
    "        if val_acc >= self.threshold:\n",
    "            self.model.stop_training = True\n",
    "\n",
    "# Define Model\n",
    "reas_model = keras.models.Sequential([\n",
    "    keras.layers.Dense(32, input_dim=X_train.shape[1], activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.6),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.6),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(3, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "# Define Parameters\n",
    "loss_function = keras.losses.CategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.005)\n",
    "callback = MyThresholdCallback(threshold=0.66)\n",
    "\n",
    "# Compile Model\n",
    "reas_model.compile(optimizer=optimizer, loss=loss_function, metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "history = reas_model.fit(X_train, y_train, epochs=1000, batch_size=1, \n",
    "    validation_data=(X_test, y_test), callbacks=[callback], verbose=0)\n",
    "\n",
    "# Print Validation Accurace of Model\n",
    "print(f\"Validation Accuracy of Model = {reas_model.evaluate(X_test, y_test, verbose=0)[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c20f0b0",
   "metadata": {},
   "source": [
    "#### Logistic Regression Model to Predict the Overall Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06ff645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the Arguments\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(text)\n",
    "X = X.toarray()\n",
    "\n",
    "# Extracting the attributes\n",
    "cogency = cleaned_df[\"cogency\"].to_numpy()\n",
    "effectiveness = cleaned_df[\"effectiveness\"].to_numpy()\n",
    "reasonableness = cleaned_df[\"reasonableness\"].to_numpy()\n",
    "\n",
    "attr_enc_map = {\n",
    "    \"1 (Low)\": np.array([0, 0, 1]),\n",
    "    \"2 (Average)\": np.array([0, 1, 0]),\n",
    "    \"3 (High)\": np.array([1, 0, 0]),\n",
    "}\n",
    "\n",
    "def encode(array):\n",
    "    temp_list = []\n",
    "    for ele in array:\n",
    "        temp_list.append(attr_enc_map[ele])\n",
    "    return np.array(temp_list)\n",
    "\n",
    "cogency = encode(cogency)\n",
    "effectiveness = encode(effectiveness)\n",
    "reasonableness = encode(reasonableness)\n",
    "\n",
    "# Adding the attributes to argument vector\n",
    "X_new = []\n",
    "for idx, x in enumerate(X):\n",
    "    temp = np.concatenate((cogency[idx], effectiveness[idx], reasonableness[idx], x))\n",
    "    X_new.append(temp)\n",
    "X = np.array(X_new)\n",
    "\n",
    "# Extract Overall Quality\n",
    "y = cleaned_df[\"overall quality\"].to_numpy()\n",
    "y = y.reshape(-1, )\n",
    "\n",
    "# Label Encoding\n",
    "encoder = LabelEncoder()\n",
    "enc_y = encoder.fit_transform(y)\n",
    "\n",
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, enc_y, test_size=0.2, random_state=110)\n",
    "\n",
    "# Train Logistic Regression Model\n",
    "qual_model = LogisticRegression(C=0.1, dual=False, fit_intercept=True,\n",
    "    penalty=\"l2\", solver=\"newton-cg\")\n",
    "qual_model.fit(X=X_train, y=y_train)\n",
    "\n",
    "# Print Validation Accuracy of Model\n",
    "pred_test = qual_model.predict(X_test)\n",
    "print(f\"Validation Accuracy of Model = {classification_report(y_test, pred_test, output_dict=True)['accuracy']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf08f9c",
   "metadata": {},
   "source": [
    "### **SAVE MODELS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c6bfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(cog_model, open(\"models/cog_model.pkl\", \"wb\"))\n",
    "pickle.dump(eff_model, open(\"models/eff_model.pkl\", \"wb\"))\n",
    "pickle.dump(reas_model, open(\"models/reas_model.pkl\", \"wb\"))\n",
    "pickle.dump(qual_model, open(\"models/qual_model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ab17b8",
   "metadata": {},
   "source": [
    "### **DEFINE 2-LAYER MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6808d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.attr_1_model = pickle.load(open(\"models/cog_model.pkl\", \"rb\"))\n",
    "        self.attr_2_model = pickle.load(open(\"models/eff_model.pkl\", \"rb\"))\n",
    "        self.attr_3_model = pickle.load(open(\"models/reas_model.pkl\", \"rb\"))\n",
    "        self.arg_model = pickle.load(open(\"models/qual_model.pkl\", \"rb\"))\n",
    "\n",
    "    def predict(self, array):\n",
    "        attr_1 = self.attr_1_model.predict(array, verbose=0)\n",
    "        attr_2 = self.attr_2_model.predict(array, verbose=0)\n",
    "        attr_3 = self.attr_3_model.predict(array, verbose=0)\n",
    "        attr_1 = self.__decode(attr_1)\n",
    "        attr_2 = self.__decode(attr_2)\n",
    "        attr_3 = self.__decode(attr_3)\n",
    "        array = self.__transform(attr_1, attr_2, attr_3, array)\n",
    "        pred = self.arg_model.predict(array)\n",
    "        return pred\n",
    "\n",
    "    def __decode(self, array):\n",
    "        new_array = []\n",
    "        label_map = {\n",
    "            0: \"1 (Low)\",\n",
    "            1: \"2 (Average)\",\n",
    "            2: \"3 (High)\",\n",
    "        }\n",
    "        for ele in array:\n",
    "            new_array.append(label_map[np.argmax(ele)])\n",
    "        return np.array(new_array)\n",
    "\n",
    "    def __transform(self, attr_1, attr_2, attr_3, array):\n",
    "        attr_1 = self.__encode(attr_1)\n",
    "        attr_2 = self.__encode(attr_2)\n",
    "        attr_3 = self.__encode(attr_3)\n",
    "        array_new = []\n",
    "        for idx, ele in enumerate(array):\n",
    "            temp = np.concatenate((attr_1[idx], attr_2[idx], attr_3[idx], ele))\n",
    "            array_new.append(temp)\n",
    "        array = np.array(array_new)\n",
    "        return array\n",
    "\n",
    "    def __encode(self, array):\n",
    "        new_array = []\n",
    "        label_map = {\n",
    "            \"1 (Low)\": np.array([0, 0, 1]),\n",
    "            \"2 (Average)\": np.array([0, 1, 0]),\n",
    "            \"3 (High)\": np.array([1, 0, 0]),\n",
    "        }\n",
    "        for ele in array:\n",
    "            new_array.append(label_map[ele])\n",
    "        return np.array(new_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092c7ae5",
   "metadata": {},
   "source": [
    "### **EVALUATE 2-LAYER MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "90698536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy of Model = 0.9759615384615384\n",
      "Validation Accuracy of Model = 0.6037735849056604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sri/Documents/UTS Research/explainable-ai-in-learning-analytics/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sri/Documents/UTS Research/explainable-ai-in-learning-analytics/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sri/Documents/UTS Research/explainable-ai-in-learning-analytics/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the Arguments\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(text)\n",
    "X = X.toarray()\n",
    "\n",
    "# Extract Overall Quality\n",
    "y = cleaned_df[\"overall quality\"].to_numpy()\n",
    "y = y.reshape(-1, )\n",
    "\n",
    "# Label Encoding\n",
    "encoder = LabelEncoder()\n",
    "enc_y = encoder.fit_transform(y)\n",
    "\n",
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, enc_y, test_size=0.2, random_state=110)\n",
    "\n",
    "# Load Model\n",
    "custom_model = CustomModel()\n",
    "\n",
    "# Evaluate Model\n",
    "pred_train = custom_model.predict(X_train)\n",
    "pred_test = custom_model.predict(X_test)\n",
    "print(f\"Training Accuracy of Model = {classification_report(y_train, pred_train, output_dict=True)['accuracy']}\")\n",
    "print(f\"Validation Accuracy of Model = {classification_report(y_test, pred_test, output_dict=True)['accuracy']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4554464a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.85      0.69        26\n",
      "           1       0.67      0.40      0.50        25\n",
      "           2       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.60        53\n",
      "   macro avg       0.42      0.42      0.40        53\n",
      "weighted avg       0.60      0.60      0.57        53\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sri/Documents/UTS Research/explainable-ai-in-learning-analytics/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sri/Documents/UTS Research/explainable-ai-in-learning-analytics/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sri/Documents/UTS Research/explainable-ai-in-learning-analytics/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6569df25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "6710d7b3-fa86-4a5b-8d13-62564d1b2f6f",
    "83563f1b-8033-472c-a0b3-f80ab3bca4d3",
    "89b9c60c-7a43-45f6-b0a7-6d6f7168694a",
    "78fda0a9-19b5-41e3-a643-2174719c86e5",
    "9c787103",
    "8fa24e34",
    "79d40667",
    "oPg7YD-cByNv",
    "X_Of2RuFByN3",
    "PcgPtowxByOB"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "1744f60b88423f066cba7163e09e742091c4b9dadbc27934e3260623efbc578c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
